# This labels the points in the first panel
text(2.8,.28, "comparison group is no cue")
text(1, .2, "Republicans", cex = .7)
text(.82, -.04, "Democrats", cex = .7)
text(1.4, .08, "Independents", cex = .7)
box()
text("oienrtgin")
text(-0.5, "oienrtgin")
upper.gop <- gop.treat + 1.96*gop.se
# This standardizes the spacing and divisions in the figure
a <- c(.8, 1, 1.2)
# I deleted this portion because it "mutes" the figure
#dev.off()
# This plots the corresponding coefficients
plot(a, liberal.treat, pch = c(15, 16, 17), axes = F, xlab = "Treatment Condition", ylab = "Increased Probability of Voting for Liberal Policy", ylim = c(-.21, .21), col  = c("dark red", "dark blue", "dark green"), xlim = c(.7, 3.3), cex = 1.5, main = "Average Treatment Effect of Policy Cues")
segments(x0 = a, y0 = lower.liberal, x1 = a, y1 = upper.liberal)
points(a+1, conservative.treat, pch = c(15, 16, 17), col  = c("dark red", "dark blue", "dark green"), cex = 1.5)
segments(x0 = a+1, y0 = lower.cons, x1 = a+1, y1 = upper.cons)
points(a+2, gop.treat, pch = c(15, 16, 17), col  = c("dark red", "dark blue", "dark green"), cex = 1.5)
segments(x0 = a+2, y0 = lower.gop, x1 = a+2, y1 = upper.gop)
# x-axis labels
axis(1, at = c(1,2,3), labels = c("Liberal Trump", "Conservative Trump", "Republicans\n in Congress"), cex.axis = .8)
axis(2, at = seq(-.2, .2, .05), las = 2, cex.axis = .8)
# dashled lines
abline(h = 0, lty = 2)
abline(v = seq(1.5, 3.5, 1), lty = 2, col = "grey")
# This labels the points in the first panel
text(2.8,.28, "comparison group is no cue")
text(1, .2, "Republicans", cex = .7)
text(.82, -.04, "Democrats", cex = .7)
text(1.4, .08, "Independents", cex = .7)
box()
text(-0.5, "oienrtgin")
plot(a, liberal.treat, pch = c(15, 16, 17), axes = F, xlab = "Treatment Condition", ylab = "Increased Probability of Voting for Liberal Policy", ylim = c(-.21, .21), col  = c("dark red", "dark blue", "dark green"), xlim = c(.7, 3.3), cex = 1.5, main = "Average Treatment Effect of Policy Cues")
segments(x0 = a, y0 = lower.liberal, x1 = a, y1 = upper.liberal)
points(a+1, conservative.treat, pch = c(15, 16, 17), col  = c("dark red", "dark blue", "dark green"), cex = 1.5)
segments(x0 = a+1, y0 = lower.cons, x1 = a+1, y1 = upper.cons)
points(a+2, gop.treat, pch = c(15, 16, 17), col  = c("dark red", "dark blue", "dark green"), cex = 1.5)
segments(x0 = a+2, y0 = lower.gop, x1 = a+2, y1 = upper.gop)
# x-axis labels
axis(1, at = c(1,2,3), labels = c("Liberal Trump", "Conservative Trump", "Republicans\n in Congress"), cex.axis = .8)
axis(2, at = seq(-.2, .2, .05), las = 2, cex.axis = .8)
# dashled lines
abline(h = 0, lty = 2)
abline(v = seq(1.5, 3.5, 1), lty = 2, col = "grey")
# This labels the points in the first panel
text(2.8,.28, "comparison group is no cue")
text(1, .2, "Republicans", cex = .7)
text(.82, -.04, "Democrats", cex = .7)
text(1.4, .08, "Independents", cex = .7)
box()
text(-0.3, "oienrtgin")
?text
# We are looking to see the effect of different cues (liberal, conservative, and conservative from congress) on Republicans, Democrats, and Independents.
# Regression for average treatment effects of a conservative, liberal, and congression conservative cue among Republicans:
# With each of the regressions, we see data filtered for Republicans:
#conservative treatment
model1 <- lm(Support ~ race_white + contrump, data = data[data$republican == 1 & (data$contrump == 1 | data$self == 1),])
#liberal treatment
model2 <- lm(Support ~ race_white + libtrump, data = data[data$republican == 1 & (data$libtrump == 1 | data$self == 1),])
#GOP treatment
model3 <- lm(support_gop ~ race_white + gopleader, data = data[data$republican == 1 & (data$gopleader == 1 | data$self == 1),])
# ****MISTAKE**** in the paper, figure 1 has the treatment effect of about -0.03 on the conservatives yet the outcome is 0.008
# Regression for average treatment effects of a conservative, liberal, and congression conservative cue among Democrats:
# With each of the regressions, we see data filtered for Democrats:
#conservative treatment
model1dem <- lm(Support ~ race_white + contrump, data = data[data$democrat == 1 & (data$contrump == 1 | data$self == 1),])
#liberal treatment
model2dem <- lm(Support ~ race_white + libtrump, data = data[data$democrat == 1 & (data$libtrump == 1 | data$self == 1),])
#GOP treatment
model3dem <- lm(support_gop ~ race_white + gopleader, data = data[data$democrat == 1 & (data$gopleader == 1 | data$self == 1),])
# Regression for average treatment effects of a conservative, liberal, and congression conservative cue among Independents:
# With each of the regressions, we see data filtered for Independents:
#conservative treatment
model1ind <- lm(Support ~ race_white + contrump, data = data[data$republican == 0 & data$democrat == 0 & (data$contrump == 1 | data$self == 1),])
#liberal treatment
model2ind <- lm(Support ~ race_white + libtrump, data = data[data$republican == 0 & data$democrat == 0 & (data$libtrump == 1 | data$self == 1),])
#GOP treatment
model3ind <- lm(support_gop ~ race_white + gopleader, data = data[data$republican == 0 & data$democrat == 0 & (data$gopleader == 1 | data$self == 1),])
# Here, the authors pull the effect of the conservative cue on each political group:
conservative.treat <- c(model1$coef[3], model1dem$coef[3], model1ind$coef[3])
# Here's the standard error for the conservative cue's effect on each political group:
conservative.se <- c(coef(summary(model1))[, "Std. Error"][3], coef(summary(model1dem))[, "Std. Error"][3], coef(summary(model1ind))[, "Std. Error"][3])
# This creates confidence intervals for the effect of conservative cues on each group:
lower.cons <- conservative.treat - 1.96*conservative.se
upper.cons <- conservative.treat + 1.96*conservative.se
# Here, the authors pull the effect of the liberal cue on each political group:
liberal.treat <- c(model2$coef[3], model2dem$coef[3], model2ind$coef[3])
# Here's the standard error for the liberal cue's effect on each political group:
liberal.se <- c(coef(summary(model2))[, "Std. Error"][3], coef(summary(model2dem))[, "Std. Error"][3], coef(summary(model2ind))[, "Std. Error"][3])
# This creates confidence intervals for the effect of liberal cues on each group:
lower.liberal <- liberal.treat - 1.96*liberal.se
upper.liberal <- liberal.treat + 1.96*liberal.se
# Here, the authors pull the effect of the GOP congressional cue on each political group:
gop.treat <- c(model3$coef[3], model3dem$coef[3], model3ind$coef[3])
# Here's the standard error for the GOP congressional cue effect on each political group:
gop.se <- c(coef(summary(model3))[, "Std. Error"][3], coef(summary(model3dem))[, "Std. Error"][3], coef(summary(model3ind))[, "Std. Error"][3])
# This creates confidence intervals for the effect of the GOP congressional cue on each group:
lower.gop <- gop.treat - 1.96*gop.se
upper.gop <- gop.treat + 1.96*gop.se
# This standardizes the spacing and divisions in the figure
a <- c(.8, 1, 1.2)
# I deleted this portion because it "mutes" the figure
#dev.off()
# This plots the corresponding coefficients
plot(a, liberal.treat, pch = c(15, 16, 17), axes = F, xlab = "Treatment Condition", ylab = "Increased Probability of Voting for Liberal Policy", ylim = c(-.21, .21), col  = c("dark red", "dark blue", "dark green"), xlim = c(.7, 3.3), cex = 1.5, main = "Average Treatment Effect of Policy Cues")
segments(x0 = a, y0 = lower.liberal, x1 = a, y1 = upper.liberal)
points(a+1, conservative.treat, pch = c(15, 16, 17), col  = c("dark red", "dark blue", "dark green"), cex = 1.5)
segments(x0 = a+1, y0 = lower.cons, x1 = a+1, y1 = upper.cons)
points(a+2, gop.treat, pch = c(15, 16, 17), col  = c("dark red", "dark blue", "dark green"), cex = 1.5)
segments(x0 = a+2, y0 = lower.gop, x1 = a+2, y1 = upper.gop)
# x-axis labels
axis(1, at = c(1,2,3), labels = c("Liberal Trump", "Conservative Trump", "Republicans\n in Congress"), cex.axis = .8)
axis(2, at = seq(-.2, .2, .05), las = 2, cex.axis = .8)
# dashled lines
abline(h = 0, lty = 2)
abline(v = seq(1.5, 3.5, 1), lty = 2, col = "grey")
# This labels the points in the first panel
text(2.8,.28, "comparison group is no cue")
text(1, .2, "Republicans", cex = .7)
text(.82, -.04, "Democrats", cex = .7)
text(1.4, .08, "Independents", cex = .7)
box()
# dir.create("pictures")
?predict
\usepackage[bottom]{footmisc}
install.packages(footmisc)
install.packages("footmisc")
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
#knitr::write_bib("bib.bib", width = 60)
library(foreign)
library(readstata13)
library(tidyverse)
library(stargazer)
library(jtools)
library(ggstance)
library(rstanarm)
#Please cite as:
# Hlavac, Marek (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables.
# R package version 5.2.2. https://CRAN.R-project.org/package=stargazer
# FIGURE 3 EXTENSION 1
# EXTENSION: TESTING FIGURE THREE WITH DEMOCRATS (ID= 1-4)
# This code will culminate in plot that looks at the treatment effect (political cue) on those with varying partisan affiliation.
# The hypothesis here states: Strong party affiliates that share party with the cue-giver are more likely to be party loyalists.
# This model is the basis of the predictions and will help determine the causal effect of political cues on different levels of partisanship among DEMOCRATS. This model estimates support of policy based on race and the interaction between cues (conservative and liberal) and political ideology:
model1 <- lm(Support ~ race_white + libtrump*pid7 + contrump*pid7, data = data[(data$contrump == 1 | data$self == 1 | data$libtrump == 1) & data$pid7 %in% c(1, 2, 3, 4),])
# This data table serves as the control - the baseline for comparison. There is no cue in this data table:
newdata = as.data.frame(cbind(rep(1, 4), rep(0, 4), rep(0, 4), seq(4, 7, 1)))
colnames(newdata) <- c("race_white", "contrump", "libtrump", "pid7")
# liberal cue as treatment on Republican partisans:
newdata1 = as.data.frame(cbind(rep(1, 4), rep(1, 4), rep(0, 4), rep(0, 4), rep(1, 4), seq(4, 7, 1)))
colnames(newdata1) <- c("race_white", "republican", "democrat", "contrump", "libtrump", "pid7")
# Like above, these are the predictions for the control and for the treatment:
plx0 <- predict(model1, newdata = newdata, type = "response", se = T)
plx1 <- predict(model1, newdata = newdata1, type = "response", se = T)
# Here we calculate the causal effect and the standard error:
diff.lib <- plx1$fit - plx0$fit
diff.lib.se <- sqrt(plx1$se.fit^2 + plx0$se.fit^2)
# These are the upper and lower confidence intervals:
upper.lib <- diff.lib + 1.96*diff.lib.se
lower.lib <- diff.lib - 1.96*diff.lib.se
# plots next to each other
par(mfrow = c(1, 2))
# Here is the plot:
#dev.new(width = 4.5, height = 7)
plot(seq(4, 7, 1), diff.lib, ylim = c(-.25, .25), pch = 16, ylab = "Estimated Average Treatment Effect", xlab = "Levels of Partisan Affiliation", axes = F, main = "Liberal Trump Treatment")
segments(x0 = c(seq(4, 7, 1), x1 = seq(4, 7, 1)), y0 = lower.lib, y1 = upper.lib, col = "#4286f480", lwd = 2)
points(seq(4, 7, 1), diff.lib, pch = 16)
abline(h = 0)
# changed titles to match change in id
axis(1, at = seq(4, 7, 1), labels = c("Independent", "Lean DEM", "Weak DEM", "Strong DEM"), cex.axis = 0.5)
axis(2, at = seq(-.25, .45, .05), las = 2)
box()
#conservative treatment: The effect of a conservative cue on those who identify with a conservative party at different degrees (pid7 = 4-7)
newdata1 = as.data.frame(cbind(rep(1, 4), rep(1, 4), rep(0, 4), seq(4, 7, 1)))
colnames(newdata1) <- c("race_white", "contrump", "libtrump", "pid7")
# These are predictions of the level of support at each Republican partisan level given the data table above with no cue:
plx0 <- predict(model1, newdata = newdata, type = "response", se = T)
#These are predictions of the level of support of a cue at each Republican partisan level given a conservative cue:
plx1 <- predict(model1, newdata = newdata1, type = "response", se = T)
# This estimates the causal effect of cues on different levels of Republican partisanship:
diff.cons <- plx1$fit - plx0$fit
# This is the staandard error of the estimates causal effects:
diff.cons.se <- sqrt(plx1$se.fit^2 + plx0$se.fit^2)
# These are the upper and lower confidence intervals the causal effect. They are calculated by adding and subtract a standard deviation times the standard error calculated above:
# IS THIS A CONF INTERVAL, 95%?, 65%?:
upper.cons <- diff.cons + 1.96*diff.cons.se
lower.cons <- diff.cons - 1.96*diff.cons.se
# This chunk plots the causal effects the same way that figure 2 did, but with partisanship on the x-axis:
#dev.new(width = 4.5, height = 7)
plot(seq(4, 7, 1), diff.cons, ylim = c(-.25, .25), pch = 16, ylab = "Estimated Average Treatment Effect", xlab = "Level of Partisan Affilitation", axes = F, main = "Conservative Trump Treatment")
segments(x0 = c(seq(4, 7, 1), x1 = seq(4, 7, 1)), y0 = lower.cons, y1 = upper.cons, col = "#d17b7b80", lwd = 2)
points(seq(4, 7, 1), diff.cons, pch = 16)
abline(h = 0)
# changed titles to match change in id
axis(1, at = seq(4, 7, 1), labels = c("Independent", "Lean DEM", "Weak DEM", "Strong DEM"), cex.axis = 0.5)
axis(2, at = seq(-.45, .25, .05), las = 2)
box()
# NOTES: SHOWS HARDLY ANY EFFECT, CONSERVATIVE CUE HAS IMPACT ON STRONG LIB - MAKES MORE LIKELY TO VOTE LIB
data <- read.dta13("Ideology_Trump.dta")
#summary(data)
#view(data)
#Table 1 - Regression Results
# In the table in the paper, the authors use the ordinary least squares regression model
# Support is for support of the policy
# These interaction models are used because people who strongly identify as conservative, for example, are more likely to be in the Republican party.
# Since I am trying to best replciate Table 1, I used the same regression components. I also kept the data parametes the same because these seem to be key in identifying which subjects we are looking at. I am still trying to find a way to better understand each variable (I may even email these authors) because there is no exhaustive list. To stay safe, I left the data parameters as they were.
# Interacting knowledge with political cues as well as key control variables:
# this model looks at the interaction between political knowledge and conservative/liberal cues
model1 <- lm(Support ~ libtrump*knowledge + contrump*knowledge + trump_approve
+ ideo5b + republican + party_strength + race_white,
# Here, the author filtered for conservative trump cues that were answered as well as liberal Trump cues that were answered. In this way, this regression looks at those who answered cues if there were any (?):
data = data[(data$contrump == 1 | data$self == 1 | data$libtrump == 1),])
# The outcome of Model 1 tells us that those with more political knwoledge are less likely to respond to liberal or conservative cues.
# Interacting party strength with political cues as well as key control variables:
model2 <- lm(Support ~ libtrump*party_strength + contrump*party_strength
+ knowledge + ideo5b + trump_approve + republican + race_white,
# Here, the author chooses data for those with above-average partisanship. They also filtered for conservative Trump cues that were answered as well as liberal Trump cues that were answered. In this way, this regression looks at those who answered cues if there were any (?):
data = data[data$pid7 %in% c(4, 5, 6, 7)
& (data$contrump == 1 | data$self == 1 | data$libtrump == 1),])
# The outcome of Model 2 shows us that strong partisans are more likely to respond to Trump cues, whether liberal or conservative.
# Interacting Trump approval with political cues as well as key control variables:
model3 <- lm(Support ~ libtrump*trump_approve + contrump*trump_approve
+ knowledge + ideo5b + republican + party_strength + race_white,
# Here, they filtered for conservative Trump cues that were answered as well as liberal Trump cues that were answered. In this way, this regression looks at those who answered cues if there were any (?):
data = data[(data$contrump == 1 | data$self == 1 | data$libtrump == 1),])
# The outcome of Model 3 shows us that those who approve of Trump are more likely to respond to Trump cues, whether liberal or conservative.
# Interacting self-placed ideology with political cues as well as key control variables:
model4 <- lm(Support ~ libtrump*ideo5b + contrump*ideo5b + knowledge
+ trump_approve + republican + party_strength + race_white,
data = data[(data$contrump == 1 | data$self == 1 | data$libtrump == 1),])
# The outcome of Model 4 shows us that those who identify as strongly conservative are more likely to respond to Trump cues, whether liberal or conservative.
cat("\\begin{table}[!htbp]")
cat("\\centering")
cat("\\caption{Interaction Models, Including Control Variables}")
cat("\\label{Table 1}")
cat("\\scalebox{.7}{")
stargazer(model1, model2, model3, model4,
type = "latex",
summary = FALSE,
title = "Interaction Models, Including Control Variables",
column.labels = c("Knowledge", "Party Strength", "Trump Approval", "Ideology"),
covariate.labels = c("Liberal Treatment", "Knowledge", "Conservative Treatment", "Trump Approval", "Ideology", "Republican", "Party Strength", "White", "Liberal treat * Knowledge", "Conservative treat * Knowledge", "Liberal treat * Party Strength", "Conservative treat * Party Strength", "Liberal treat * Trump Approval", "Conservative treat * Trump Approval", "Liberal treat * Ideology", "Conservative treat * Ideology"),
column.sep.width = "-10pt",
font.size = "small",
omit.stat = "all",
float = FALSE)
cat("}") # for the end of the scalebox
cat("\\end{table}")
?stargazer
citation()
\usepackage[backend=biber, style=numeric, defernumbers]{biblatex}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
knitr::write_bib("bib.bib", width = 60)
#knitr::write_bib("bib.bib", width = 60)
library(foreign)
library(readstata13)
library(tidyverse)
library(stargazer)
library(jtools)
library(ggstance)
library(rstanarm)
#Please cite as:
# Hlavac, Marek (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables.
# R package version 5.2.2. https://CRAN.R-project.org/package=stargazer
dir.create("data")
data <- read.dta13("data"/"Ideology_Trump.dta")
?read.csv
library(foreign)
library(readstata13)
data <- read.dta13("data/Ideology_Trump.dta")
mturk <- read.csv("data/Trump_Obama.csv")
# dir.create("data")
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
knitr::write_bib("bib.bib", width = 60)
#knitr::write_bib("bib.bib", width = 60)
library(foreign)
library(readstata13)
library(tidyverse)
library(stargazer)
library(jtools)
library(ggstance)
library(rstanarm)
data <- read.dta13("data/Ideology_Trump.dta")
#summary(data)
#view(data)
#Table 1 - Regression Results
# In the table in the paper, the authors use the ordinary least squares regression model
# Support is for support of the policy
# These interaction models are used because people who strongly identify as conservative, for example, are more likely to be in the Republican party.
# Since I am trying to best replciate Table 1, I used the same regression components. I also kept the data parametes the same because these seem to be key in identifying which subjects we are looking at. I am still trying to find a way to better understand each variable (I may even email these authors) because there is no exhaustive list. To stay safe, I left the data parameters as they were.
# Interacting knowledge with political cues as well as key control variables:
# this model looks at the interaction between political knowledge and conservative/liberal cues
model1 <- lm(Support ~ libtrump*knowledge + contrump*knowledge + trump_approve
+ ideo5b + republican + party_strength + race_white,
# Here, the author filtered for conservative trump cues that were answered as well as liberal Trump cues that were answered. In this way, this regression looks at those who answered cues if there were any (?):
data = data[(data$contrump == 1 | data$self == 1 | data$libtrump == 1),])
# The outcome of Model 1 tells us that those with more political knwoledge are less likely to respond to liberal or conservative cues.
# Interacting party strength with political cues as well as key control variables:
model2 <- lm(Support ~ libtrump*party_strength + contrump*party_strength
+ knowledge + ideo5b + trump_approve + republican + race_white,
# Here, the author chooses data for those with above-average partisanship. They also filtered for conservative Trump cues that were answered as well as liberal Trump cues that were answered. In this way, this regression looks at those who answered cues if there were any (?):
data = data[data$pid7 %in% c(4, 5, 6, 7)
& (data$contrump == 1 | data$self == 1 | data$libtrump == 1),])
# The outcome of Model 2 shows us that strong partisans are more likely to respond to Trump cues, whether liberal or conservative.
# Interacting Trump approval with political cues as well as key control variables:
model3 <- lm(Support ~ libtrump*trump_approve + contrump*trump_approve
+ knowledge + ideo5b + republican + party_strength + race_white,
# Here, they filtered for conservative Trump cues that were answered as well as liberal Trump cues that were answered. In this way, this regression looks at those who answered cues if there were any (?):
data = data[(data$contrump == 1 | data$self == 1 | data$libtrump == 1),])
# The outcome of Model 3 shows us that those who approve of Trump are more likely to respond to Trump cues, whether liberal or conservative.
# Interacting self-placed ideology with political cues as well as key control variables:
model4 <- lm(Support ~ libtrump*ideo5b + contrump*ideo5b + knowledge
+ trump_approve + republican + party_strength + race_white,
data = data[(data$contrump == 1 | data$self == 1 | data$libtrump == 1),])
# The outcome of Model 4 shows us that those who identify as strongly conservative are more likely to respond to Trump cues, whether liberal or conservative.
cat("\\begin{table}[!htbp]")
cat("\\centering")
cat("\\caption{Interaction Models, Including Control Variables}")
cat("\\label{Table 1}")
cat("\\scalebox{.7}{")
stargazer(model1, model2, model3, model4,
type = "latex",
title = "Interaction Models, Including Control Variables",
summary = FALSE,
column.labels = c("Knowledge", "Party Strength", "Trump Approval", "Ideology"),
covariate.labels = c("Liberal Treatment", "Knowledge", "Conservative Treatment", "Trump Approval", "Ideology", "Republican", "Party Strength", "White", "Liberal treat * Knowledge", "Conservative treat * Knowledge", "Liberal treat * Party Strength", "Conservative treat * Party Strength", "Liberal treat * Trump Approval", "Conservative treat * Trump Approval", "Liberal treat * Ideology", "Conservative treat * Ideology"),
column.sep.width = "-10pt",
font.size = "small",
omit.stat = "all",
float = FALSE,
notes = "\\parbox[t]{10cm}{These are the main linear regressions used by Barber and Pope to test their four hypotheses. I replicated their table and got the same results. I displyed this table using the stargazer function.}")
cat("}") # for the end of the scalebox
cat("\\end{table}")
# We are looking to see the effect of different cues (liberal, conservative, and conservative from congress) on Republicans, Democrats, and Independents.
# Regression for average treatment effects of a conservative, liberal, and congression conservative cue among Republicans:
# With each of the regressions, we see data filtered for Republicans:
#conservative treatment
model1 <- lm(Support ~ race_white + contrump, data = data[data$republican == 1 & (data$contrump == 1 | data$self == 1),])
#liberal treatment
model2 <- lm(Support ~ race_white + libtrump, data = data[data$republican == 1 & (data$libtrump == 1 | data$self == 1),])
#GOP treatment
model3 <- lm(support_gop ~ race_white + gopleader, data = data[data$republican == 1 & (data$gopleader == 1 | data$self == 1),])
# ****MISTAKE**** in the paper, figure 1 has the treatment effect of about -0.03 on the conservatives yet the outcome is 0.008
# Regression for average treatment effects of a conservative, liberal, and congression conservative cue among Democrats:
# With each of the regressions, we see data filtered for Democrats:
#conservative treatment
model1dem <- lm(Support ~ race_white + contrump, data = data[data$democrat == 1 & (data$contrump == 1 | data$self == 1),])
#liberal treatment
model2dem <- lm(Support ~ race_white + libtrump, data = data[data$democrat == 1 & (data$libtrump == 1 | data$self == 1),])
#GOP treatment
model3dem <- lm(support_gop ~ race_white + gopleader, data = data[data$democrat == 1 & (data$gopleader == 1 | data$self == 1),])
# Regression for average treatment effects of a conservative, liberal, and congression conservative cue among Independents:
# With each of the regressions, we see data filtered for Independents:
#conservative treatment
model1ind <- lm(Support ~ race_white + contrump, data = data[data$republican == 0 & data$democrat == 0 & (data$contrump == 1 | data$self == 1),])
#liberal treatment
model2ind <- lm(Support ~ race_white + libtrump, data = data[data$republican == 0 & data$democrat == 0 & (data$libtrump == 1 | data$self == 1),])
#GOP treatment
model3ind <- lm(support_gop ~ race_white + gopleader, data = data[data$republican == 0 & data$democrat == 0 & (data$gopleader == 1 | data$self == 1),])
# Here, the authors pull the effect of the conservative cue on each political group:
conservative.treat <- c(model1$coef[3], model1dem$coef[3], model1ind$coef[3])
# Here's the standard error for the conservative cue's effect on each political group:
conservative.se <- c(coef(summary(model1))[, "Std. Error"][3], coef(summary(model1dem))[, "Std. Error"][3], coef(summary(model1ind))[, "Std. Error"][3])
# This creates confidence intervals for the effect of conservative cues on each group:
lower.cons <- conservative.treat - 1.96*conservative.se
upper.cons <- conservative.treat + 1.96*conservative.se
# Here, the authors pull the effect of the liberal cue on each political group:
liberal.treat <- c(model2$coef[3], model2dem$coef[3], model2ind$coef[3])
# Here's the standard error for the liberal cue's effect on each political group:
liberal.se <- c(coef(summary(model2))[, "Std. Error"][3], coef(summary(model2dem))[, "Std. Error"][3], coef(summary(model2ind))[, "Std. Error"][3])
# This creates confidence intervals for the effect of liberal cues on each group:
lower.liberal <- liberal.treat - 1.96*liberal.se
upper.liberal <- liberal.treat + 1.96*liberal.se
# Here, the authors pull the effect of the GOP congressional cue on each political group:
gop.treat <- c(model3$coef[3], model3dem$coef[3], model3ind$coef[3])
# Here's the standard error for the GOP congressional cue effect on each political group:
gop.se <- c(coef(summary(model3))[, "Std. Error"][3], coef(summary(model3dem))[, "Std. Error"][3], coef(summary(model3ind))[, "Std. Error"][3])
# This creates confidence intervals for the effect of the GOP congressional cue on each group:
lower.gop <- gop.treat - 1.96*gop.se
upper.gop <- gop.treat + 1.96*gop.se
# This standardizes the spacing and divisions in the figure
a <- c(.8, 1, 1.2)
# I deleted this portion becauase it "mutes" the figure
#dev.off()
# This plots the corresponding coefficients
plot(a, liberal.treat, pch = c(15, 16, 17), axes = F, xlab = "Treatment Condition", ylab = "Increased Probability of Voting for Liberal Policy", ylim = c(-.21, .21), col  = c("dark red", "dark blue", "dark green"), xlim = c(.7, 3.3), cex = 1.5, main = "Average Treatment Effect of Policy Cues")
segments(x0 = a, y0 = lower.liberal, x1 = a, y1 = upper.liberal)
points(a+1, conservative.treat, pch = c(15, 16, 17), col  = c("dark red", "dark blue", "dark green"), cex = 1.5)
segments(x0 = a+1, y0 = lower.cons, x1 = a+1, y1 = upper.cons)
points(a+2, gop.treat, pch = c(15, 16, 17), col  = c("dark red", "dark blue", "dark green"), cex = 1.5)
segments(x0 = a+2, y0 = lower.gop, x1 = a+2, y1 = upper.gop)
# x-axis labels
axis(1, at = c(1,2,3), labels = c("Liberal Trump", "Conservative Trump", "Republicans\n in Congress"), cex.axis = .8)
axis(2, at = seq(-.2, .2, .05), las = 2, cex.axis = .8)
# dashled lines
abline(h = 0, lty = 2)
abline(v = seq(1.5, 3.5, 1), lty = 2, col = "grey")
# This labels the points in the first panel
text(2.8,.28, "comparison group is no cue")
text(1.14, .16, "Republicans", cex = .7)
text(.82, -.05, "Democrats", cex = .7)
text(1.5, .06, "Independents", cex = .7)
box()
# FIGURE 2 EXTENSION
# This code will culminate in plot that looks at the treatment effect (political cue) on those with varying political knowledge. # The hypothesis here states: Only the those with less knowledge should react to the cue and behave as party loyalists presumably because the knowledgeable gain little from the treatment (political cue).
# Model 1 is a linear regression that looks that the impact of political knowledge on response to cues. The authors include an interaction between liberal cues and knowledge as well as conservative cues and knowledge to see if there is any discrepancy between cues' effects with knowledge:
modelstan <- stan_glm(Support ~ race_white + libtrump*knowledge + contrump*knowledge, data = data[(data$contrump == 1 | data$self == 1 | data$libtrump == 1),], refresh = 0, family = "binomial")
# Now we are looking at the liberal cue's causal effect at each interval of knowledge:
#control: there is no cue in this data table
newdata = as.data.frame(cbind(rep(1, 9), rep(0, 9), rep(0, 9), seq(0, 8, 1)))
colnames(newdata) <- c("race_white", "contrump", "libtrump", "knowledge")
# This data frame designates the liberal cue for each level of knowledge:
newdata1 = as.data.frame(cbind(rep(1, 9), rep(0, 9), rep(1,9), seq(0, 8, 1)))
colnames(newdata1) <- c("race_white", "contrump", "libtrump", "knowledge")
# This table predicts the response at each level of knowledge given no cue.
plx0 <- posterior_linpred(modelstan, newdata = newdata, transfor = TRUE)
# This table predicts the response at each level of knowledge given a liberal cue.
plx1 <- posterior_linpred(modelstan, newdata = newdata1, transform = TRUE)
# This is the treatment effect: the difference between response at each knowledge level with a liberal cue and a response at teach knowledge level with a cue. It is the causal effect of the liberal treatment.
diff.l <- plx1 - plx0
diff.lib <- colMeans(diff.l)
# I will use the 95% credible interval to create an uncertainty measure:
# DO YOU TAKE QUANTILE OF DIFFERENCE OR JUST ONE
k0ci25l <- quantile(diff.l[,1], 0.025)
k1ci25l <- quantile(diff.l[,2], 0.025)
k2ci25l <- quantile(diff.l[,3], 0.025)
k3ci25l <- quantile(diff.l[,4], 0.025)
k4ci25l <- quantile(diff.l[,5], 0.025)
k5ci25l <- quantile(diff.l[,6], 0.025)
k6ci25l <- quantile(diff.l[,7], 0.025)
k7ci25l <- quantile(diff.l[,8], 0.025)
k8ci25l <- quantile(diff.l[,9], 0.025)
k0ci95l <- quantile(diff.l[,1], 0.975)
k1ci95l <- quantile(diff.l[,2], 0.975)
k2ci95l <- quantile(diff.l[,3], 0.975)
k3ci95l <- quantile(diff.l[,4], 0.975)
k4ci95l <- quantile(diff.l[,5], 0.975)
k5ci95l <- quantile(diff.l[,6], 0.975)
k6ci95l <- quantile(diff.l[,7], 0.975)
k7ci95l <- quantile(diff.l[,8], 0.975)
k8ci95l <- quantile(diff.l[,9], 0.975)
# These are the upper and lower credible levels that will be plotted:
upper.lib <- c(k0ci95l, k1ci95l, k2ci95l, k3ci95l, k4ci95l, k5ci95l, k6ci95l, k7ci95l, k8ci95l)
lower.lib <- c(k0ci25l, k1ci25l, k2ci25l, k3ci25l, k4ci25l, k5ci25l, k6ci25l, k7ci25l, k8ci25l)
# will put plots together
par(mfrow = c(1, 2))
# the plotting here is the SAME as above
#dev.new(width = 4.5, height = 7)
plot(seq(0, 8, 1), diff.lib, ylim = c(-.25, .15), pch = 16, ylab = "Estimated Average Treatment Effect", xlab = "Level of Political Knowledge", axes = F, main = "Liberal Trump Treatment")
segments(x0 = c(seq(0, 8, 1), x1 = seq(0, 8, 1)), y0 = lower.lib, y1 = upper.lib, col = "#4286f480", lwd = 2)
points(seq(0, 8, 1), diff.lib, pch = 16)
abline(h = 0)
axis(1, at = seq(0, 8, 1))
axis(2, at = seq(-.25, .15, .05), las = 2)
box()
# Looking at the conservative cue's impact on each level of knowledge:
#conservative treatment: this data table contains a conservative cue for each level of knowledge
newdata1 = as.data.frame(cbind(rep(1, 9), rep(1, 9), rep(0,9), seq(0, 8, 1)))
colnames(newdata1) <- c("race_white", "contrump", "libtrump", "knowledge")
# This table predicts the response at each level of knowledge given no cue.
plx0 <- posterior_linpred(modelstan, newdata = newdata, type = "response", transform = TRUE, se = T)
# This table predicts the response at each level of knowledge given a conservative cue.
plx1 <- posterior_linpred(modelstan, newdata = newdata1, type = "response", transform = TRUE, se = T)
# NOT REALLY SURE WHY THE MODEL1 IS USED IN FIRST PREDICT - WHAT DOES PLX0 DO?
# This is the treatment effect: the difference between response at each knowledge level with a conservative cue and a response at teach knowledge level with a cue. It is the causal effect of the conservative treatment.
diff <- plx1 - plx0
diff.cons <- colMeans(diff)
# I will use the 95% credible interval to create an uncertainty measure:
# DO YOU TAKE QUANTILE OF DIFFERENCE OR JUST ONE
k0ci25 <- quantile(diff[,1], 0.025)
k1ci25 <- quantile(diff[,2], 0.025)
k2ci25 <- quantile(diff[,3], 0.025)
k3ci25 <- quantile(diff[,4], 0.025)
k4ci25 <- quantile(diff[,5], 0.025)
k5ci25 <- quantile(diff[,6], 0.025)
k6ci25 <- quantile(diff[,7], 0.025)
k7ci25 <- quantile(diff[,8], 0.025)
k8ci25 <- quantile(diff[,9], 0.025)
k0ci95 <- quantile(diff[,1], 0.975)
k1ci95 <- quantile(diff[,2], 0.975)
k2ci95 <- quantile(diff[,3], 0.975)
k3ci95 <- quantile(diff[,4], 0.975)
k4ci95 <- quantile(diff[,5], 0.975)
k5ci95 <- quantile(diff[,6], 0.975)
k6ci95 <- quantile(diff[,7], 0.975)
k7ci95 <- quantile(diff[,8], 0.975)
k8ci95 <- quantile(diff[,9], 0.975)
# These are the upper and lower credible levels that will be plotted:
upper.cons <- c(k0ci95, k1ci95, k2ci95, k3ci95, k4ci95, k5ci95, k6ci95, k7ci95, k8ci95)
lower.cons <- c(k0ci25, k1ci25, k2ci25, k3ci25, k4ci25, k5ci25, k6ci25, k7ci25, k8ci25)
# This plots the diff.cons (the causal effect of a conservative cue at each level of knowledge) with the upper and lower confidence intervals crafted with the standard error. The function also gives the range of the plots, the titles, and the axes.
# These are just the points, titles, and axes:
plot(seq(0, 8, 1), diff.cons, ylim = c(-.25, .15), pch = 16, ylab = "Estimated Average Treatment Effect", xlab = "Level of Political Knowledge", axes = F, main = "Conservative Trump Treatment")
#This adds on the upper and lower confidence intervals showing the uncertainty of the estimate. It also designates the color of the bars denoting uncertainty:
segments(x0 = c(seq(0, 8, 1), x1 = seq(0, 8, 1)), y0 = lower.cons, y1 = upper.cons, col = "#d17b7b80", lwd = 2)
# This brings the points back in front of the lines of uncertainty:
points(seq(0, 8, 1), diff.cons, pch = 16)
abline(h = 0)
# This adds an axis at zero:
axis(1, at = seq(0, 8, 1))
# This adds the y-axis and denotes the range:
axis(2, at = seq(-.25, .15, .05), las = 2)
# This puts a border around the plot:
box()
# dir.create("data")
dir.create("original_paper")
\newpage
\usepackage[bottom]{footmisc}
## Extension 3: Binomial Regression instead of Linear on Barber and Pope's Figure 2
Finally, I want to take Figure 2 and see if I can create a more robust model. These regression models are currently linear and use interactions to predict the outcome of a cue given something like partisanship, ideology, etc. The authors then use the predict function to predict support of a policy and to find the causal effect of recieving a cue by subtracting the response outcome for the treated from a fake data set of untreated individuals. I believe that by using a binomial regression and the posterior_linpred function, I could create a more robust model and prediction, thus achieving a more accurate causal effect.
Whereas the authors perform an OLS regression - a Frequentist appraoch - I use an Bayesian approach. The Frequentist approach can be useful as it looks just at the data given to illustrate trends and draw conclusions. The Bayesian appraoch, however seems to be more robust as it uses prior information when making inferences, meaning that it does not merely summarize, but models future outcomes as well. Moreover, in a Bayesian approach, all inferences are "probabalistic and can be represented by random simulations" which is beneficial when summarizing uncertainty or using "regression models for predictions."^[@RAOS, p. 16]
